{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incomplete-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import random\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time \n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35147b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doGPU=False\n",
    "if (doGPU):\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "963ea4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('faces_python.pkl', 'rb') as f:\n",
    "    face_data = pickle.load(f).astype(np.float32)\n",
    "with open('nonfaces_python.pkl', 'rb') as f:\n",
    "    nonface_data = pickle.load(f).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f097ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_data shape: (13233, 1024)\n",
      "nonface_data shape: (50000, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(\"face_data shape:\", face_data.shape)\n",
    "print(\"nonface_data shape:\", nonface_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76d6c178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_data min, max: -1.0 1.0\n",
      "nonface_data min, max: -1.0 1.0\n",
      "face_data min, max: -3.0 1.0\n",
      "nonface_data min, max: -1.0078431 -0.99215686\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "print(\"face_data min, max:\", face_data.min(), face_data.max())\n",
    "print(\"nonface_data min, max:\", nonface_data.min(), nonface_data.max())\n",
    "\n",
    "# [0.0, 255.0] -> [0, 1]\n",
    "nonface_data /= 255.\n",
    "\n",
    "# [0, 1] -> [-1, 1]\n",
    "face_data -= 0.5\n",
    "face_data *= 2\n",
    "\n",
    "nonface_data -= 0.5\n",
    "nonface_data *= 2\n",
    "\n",
    "print(\"face_data min, max:\", face_data.min(), face_data.max())\n",
    "print(\"nonface_data min, max:\", nonface_data.min(), nonface_data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0acc012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "train_test_split = 0.8\n",
    "\n",
    "# prepare faces\n",
    "tmp1 = np.round(face_data.shape[0]*train_test_split).astype(int)\n",
    "train_ct1 = np.ones(tmp1) \n",
    "test_ct1 = np.ones((face_data.shape[0]-tmp1,1))\n",
    "train_ci1 = face_data[:tmp1,:] \n",
    "test_ci1 = face_data[tmp1:,:]\n",
    "\n",
    "# prepare non-faces\n",
    "# note that CIFAR has a lot more images, so here we \n",
    "# restrict also this dataset to the same number of images\n",
    "# as the face dataset!\n",
    "tmp2 = np.round(face_data.shape[0]*train_test_split).astype(int)\n",
    "train_ct2 = np.zeros(tmp2) \n",
    "test_ct2 = np.zeros((face_data.shape[0]-tmp2,1))\n",
    "train_ci2 = nonface_data[:tmp2,:] \n",
    "test_ci2 = nonface_data[tmp2:face_data.shape[0],:]\n",
    "\n",
    "# now concatenate arrays\n",
    "train_ct12 = np.concatenate((train_ct1,train_ct2),axis=0)\n",
    "train_ci12 = np.concatenate((train_ci1,train_ci2),axis=0).reshape(-1,1,32,32)\n",
    "\n",
    "test_ct12 = np.concatenate((test_ct1,test_ct2),axis=0)\n",
    "test_ci12 = np.concatenate((test_ci1,test_ci2),axis=0).reshape(-1,1,32,32)\n",
    "\n",
    "#\n",
    "train_ct12 = torch.tensor(train_ct12, dtype=torch.long)\n",
    "train_ci12 = torch.tensor(train_ci12, dtype=torch.float32)\n",
    "test_ct12 = torch.tensor(test_ct12, dtype=torch.long)\n",
    "test_ci12 = torch.tensor(test_ci12, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "871b48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset and dataloader\n",
    "trainset = TensorDataset(train_ci12, train_ct12)\n",
    "testset = TensorDataset(test_ci12, test_ct12)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59d8f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(face_data[0].reshape(32,32))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "designing-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a small CNN based on the nn.Module class\n",
    "class CNN(nn.Module):\n",
    "    # every nn needs the constructor\n",
    "    def __init__(self, num_layer, size, increase):\n",
    "        # call the pytorch constructor of the parent class\n",
    "        super().__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.size = size\n",
    "        self.increase = increase\n",
    "        self.padd = int(self.size/2)\n",
    "        # first convolutional layer\n",
    "        # 3 input layers [because of color images]\n",
    "        # 16 filters with 5x5 pixels each\n",
    "        self.conv1 = nn.Conv2d(1, 8, self.size, padding=self.padd)\n",
    "        self.conv2 = nn.Conv2d(8, 16, self.size, padding=self.padd)\n",
    "        self.conv3 = nn.Conv2d(16, 32, self.size,padding=self.padd)\n",
    "        self.conv4 = nn.Conv2d(32, 64, self.size, padding=self.padd)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(1, 16, self.size, padding=self.padd)\n",
    "        self.conv6 = nn.Conv2d(16, 16, self.size, padding=self.padd)\n",
    "\n",
    "        # pool using 2x2 grid [downsampling]\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # fully connected layer \n",
    "        self.fc1 = nn.Linear(2 ** (self.num_layer+2) * int(32/(2*self.num_layer)) * int(32/(2*self.num_layer)), 2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(16 * int(32/(2*self.num_layer)) * int(32/(2*self.num_layer)), 2)\n",
    "    # every nn needs a forward pass function which takes data x\n",
    "    # as input and returns x as output\n",
    "    # the forward function uses the layers defined in the \n",
    "    # constructor to make the network architecture\n",
    "    def forward(self, x):\n",
    "        if self.increase == True:\n",
    "            if self.num_layer == 2:\n",
    "                # Relu of first CONV and pool\n",
    "                x = self.pool(F.relu(self.conv1(x)))\n",
    "                # Relu of second CONV and pool\n",
    "                x = self.pool(F.relu(self.conv2(x)))\n",
    "                # flatten output so that it fits into fc layer\n",
    "                x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "                x = self.fc1(x)\n",
    "\n",
    "            elif self.num_layer == 3:\n",
    "                x = self.pool(F.relu(self.conv1(x)))\n",
    "                x = self.pool(F.relu(self.conv2(x)))\n",
    "                x = self.pool(F.relu(self.conv3(x)))\n",
    "                x = torch.flatten(x, 1)\n",
    "                x = self.fc1(x)\n",
    "\n",
    "            elif self.num_layer == 4:\n",
    "                x = self.pool(F.relu(self.conv1(x)))\n",
    "                x = self.pool(F.relu(self.conv2(x)))\n",
    "                x = self.pool(F.relu(self.conv3(x)))\n",
    "                x = self.pool(F.relu(self.conv4(x)))\n",
    "                x = torch.flatten(x, 1)\n",
    "                x = self.fc1(x)\n",
    "            else:\n",
    "                print('Error')\n",
    "        else :\n",
    "            if self.num_layer == 2:\n",
    "                x = self.pool(F.relu(self.conv5(x)))\n",
    "                x = self.pool(F.relu(self.conv6(x)))\n",
    "                x = torch.flatten(x, 1) \n",
    "                x = self.fc2(x)\n",
    "\n",
    "            elif self.num_layer == 3:\n",
    "                x = self.pool(F.relu(self.conv5(x)))\n",
    "                x = self.pool(F.relu(self.conv6(x)))\n",
    "                x = self.pool(F.relu(self.conv6(x)))\n",
    "                x = torch.flatten(x, 1)\n",
    "                x = self.fc2(x)\n",
    "\n",
    "            elif self.num_layer == 4:\n",
    "                x = self.pool(F.relu(self.conv5(x)))\n",
    "                x = self.pool(F.relu(self.conv6(x)))\n",
    "                x = self.pool(F.relu(self.conv6(x)))\n",
    "                x = self.pool(F.relu(self.conv6(x)))\n",
    "                x = torch.flatten(x, 1)\n",
    "                x = self.fc2(x)\n",
    "            else:\n",
    "                print('Error')\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d0708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Test:\n",
    "    def __init__(self, num_layer, size, b_increase):\n",
    "        self.num_layer = num_layer\n",
    "        self.size = size\n",
    "        self.b_increase = b_increase\n",
    "\n",
    "        self.net = CNN(self.num_layer, self.size, self.b_increase).to(device)\n",
    "        self.criterion = nn.CrossEntropyLoss() # the cross entropy loss\n",
    "        self.optimizer = optim.SGD(self.net.parameters(), lr=0.001, momentum=0.9) # define the optimizer\n",
    "        self.running_loss = []\n",
    "        self.acc = 0\n",
    "\n",
    "    def training(self):\n",
    "        start_time = time.time()\n",
    "        for epoch in range(10):  # loop over the dataset multiple times\n",
    "            # load a batch of data\n",
    "            for inputs, labels in train_loader:\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # forward + loss + backward + optimize\n",
    "                outputs = self.net(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # print statistics\n",
    "                self.running_loss.append(loss.item())\n",
    "                \n",
    "        print('Finished Training')\n",
    "        end_time = time.time()\n",
    "        self.training_time = end_time - start_time\n",
    "\n",
    "    def test(self):\n",
    "        number_corr = 0\n",
    "        \n",
    "        # again no gradients needed\n",
    "        with torch.no_grad():\n",
    "            # go through all elements in the test set\n",
    "            for inputs, labels in test_loader:\n",
    "                # again push them to device\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                # we need the forward pass\n",
    "                outputs = self.net(inputs)\n",
    "                output_label = outputs.argmax(dim=1)\n",
    "\n",
    "                number_corr += (output_label == labels).sum().item()\n",
    "                \n",
    "            self.acc = number_corr / len(test_loader)\n",
    "\n",
    "    def draw_plot(self):\n",
    "        filter_list = [[8, 16, 32, 64], [16, 16, 16, 16]]\n",
    "\n",
    "        print('number of layers : ', self.num_layer)\n",
    "        print('number of filters : ', filter_list[self.b_increase][:self.num_layer])\n",
    "        print('size of filters : ', self.size)\n",
    "        print('total training time : ', self.training_time)\n",
    "        print('final accuracy : ', self.acc)\n",
    "        \n",
    "        plt.plot(self.running_loss)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss curves')\n",
    "        plt.grid()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de1aff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = [2, 3, 4]\n",
    "b_filter = [0, 1]\n",
    "size_list = [3, 5]\n",
    "\n",
    "all_network = []\n",
    "for num_lay in layer_list:\n",
    "    for bo_fil in b_filter:\n",
    "        for size in size_list:\n",
    "            all_network.append(Train_Test(num_lay, size, bo_fil))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756a2592",
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in all_network:\n",
    "    network.training()\n",
    "    network.test()\n",
    "    network.draw_plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-religion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-handy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e17245beed66d97676295f18f5af02f52c1ff0b20014505018e20bb50c7c46d6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
